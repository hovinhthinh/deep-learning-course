\documentclass{article}

\usepackage{dirtree}

\usepackage[
  height=9in,      % height of the text block
  width=7.5in,       % width of the text block
  top=78pt,        % distance of the text block from the top of the page
  headheight=48pt, % height for the header block
  headsep=12pt,    % distance from the header block to the text block
  heightrounded,   % ensure an integer number of lines
        % show the main blocks
  verbose,         % show the values of the parameters in the log file
]{geometry}
\setlength{\parindent}{0pt}
\usepackage{amsmath}
\usepackage{courier}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{fancyhdr}
\usepackage{mathtools}

\pagestyle{fancy}
\fancyhead[L]{Pattern and Speech Recognition WS1617\\ Assignment 01}
\fancyhead[R]{ Vinh Thinh Ho (2562630) \\ Noshaba Cheema (2562653)}

\usepackage{graphicx}
\graphicspath{ {/home/prabal/Documents/SNLP/} }

\renewcommand{\headrulewidth}{0.4pt}

\begin{document}

\section*{1 Linear Algebra}
\subsection*{1)}
Because $M$ is real symmetric matrix, we can use eigendecomposition to decompose $M$ into: $ M = UDU^{T}$, in which $U$ is an orthogonal matrix, and $D$ is a diagonal matrix containing all eigenvalues of $M: D = diag(\lambda_{1}, \lambda_{2},..., \lambda_{k})$. Hence,
\begin{align*}
x^{T}Mx &= x^{T}(UDU^{T})x\\
&= (x^{T}U)D(x^{T}U)^{T}
\end{align*}
Set $y = x^{T}U$, we have:
\begin{align*}
x^{T}Mx &= yDy^{T}\\
&= \sum\limits_{i}^{k}\lambda_{i} \cdot y_{i}^2\;\;\;\;\;\text{(Because $D$ is diagonal matrix)}
\end{align*}
So,
\begin{align*}
\iff & \lambda_{min}\sum\limits_{i}^{k}y_{i}^2 \leq x^{T}Mx \leq  \lambda_{max}\sum\limits_{i}^{k}y_{i}^2\\
\iff & \lambda_{min} \cdot y^{T}y \leq x^{T}Mx \leq  \lambda_{max} \cdot y^{T}y
\end{align*}
On the other hand, $y^{T}y = (x^{T}U)(x^{T}U)^{T} = x^{T}UU^{T}x = x^{T}x$ (Because $U$ is orthogonal). Then we have:

\begin{align*}
& \lambda_{min} \cdot x^{T}x \leq x^{T}Mx \leq  \lambda_{max} \cdot x^{T}x\\
\iff & \lambda_{min} \cdot \|x\|_{2}^{2} \leq x^{T}Mx \leq  \lambda_{max} \cdot \|x\|_{2}^{2}\\
\iff & \lambda_{min} \leq \frac{x^{T}Mx}{\|x\|_{2}^{2}} \leq \lambda_{max}
\end{align*}

\subsection*{2)}
Because $M$ is real symmetric matrix, we can use eigendecomposition to decompose $M$ into: $ M = UDU^{T}$, in which $U$ is an orthogonal matrix, and $D$ is a diagonal matrix containing all eigenvalues of $M$. Hence,
\begin{align*}
M^{100} &= (UDU^{T})^{100}\\
&= UD^{100}U^{T}\;\;\;\;\;(because\;UU^{T} = I, since\;U\;is\;orthogonal)
\end{align*}
To calculate $D^{100}$, assume $D = diag(\lambda_{1}, \lambda_{2},..,\lambda_{k})$, then $D^{100} = diag(\lambda_{1}^{100}, \lambda_{2}^{100},..,\lambda_{k}^{100})$.
\subsection*{3)}
(i) We can see that this matrix is symmetric and contains only real number, so it is a Hermitian matrix, hence, it is positive definite iff its principal minors are positive, more formally:\\
$\bullet\;
\begin{vmatrix}
2
\end{vmatrix}
 > 0$ (Obvious)\\\\$
\bullet\;{
\begin{vmatrix}
2 & -1\\
-1 & 3
\end{vmatrix}
} > 0$ (Obvious)\\\\$
\bullet\;{
\begin{vmatrix}
2 & -1 & -1\\
-1 & 3 & -1\\
-1 & -1 & x
\end{vmatrix}
} > 0 \iff x > \frac{7}{5}
$

$\Rightarrow$ We conclude that $x > \frac{7}{5}$\\\\
(ii) We transform matrix into row echelon form:
\begin{align*}
& \begin{vmatrix}
2 & -1 & -1\\
-1 & 3 & -1\\
-1 & -1 & x
\end{vmatrix}\\
\equiv & \begin{vmatrix}
1 & -0.5 & -0.5\\
0 & 2.5 & -1.5\\
0 & -1.5 & \frac{2x - 1}{2}\\
\end{vmatrix}\\
\equiv & \begin{vmatrix}
1 & -0.5 & -0.5\\
0 & 1 & -0.6\\
0 & 0 & \frac{2x - 1}{2} - 0.9\\
\end{vmatrix}
\end{align*}

$\Rightarrow$ We conclude that to have rank-2 matrix:
\begin{align*}
\frac{2x - 1}{2} - 0.9 &= 0\\
x &= \frac{7}{5}
\end{align*}

\subsection*{4)}
(i) Vector (1,1,1) is in null space of matrix, hence,
\begin{align*}
\begin{bmatrix}
2 & -1 & -1\\
-1 & 2 & -1\\
-5 & 3 & y
\end{bmatrix}.
\begin{bmatrix} 1\\1\\1\end{bmatrix} &= 0\\
y &= -2
\end{align*}

(ii) Sum of eigenvalues is equal to the trace of matrix $\Rightarrow$ to have sum of eigenvalues is equal to 0, we need $2 + 2 + y = 0 \iff y = -4$.
\subsection*{5)}
Suppose vector $x$ has number of dimensions $k$. We have:
\begin{align*}
\|x\|_1 &= \sum\limits_{i}^{k}|x_{i}|\\
\text{and}\ \|x\|_{\infty} &= \max\limits_{i}^{k}|x_{i}|
\end{align*}
Hence, we can conclude:
\begin{align*}
\|x\|_{\infty} \leq \|x\|_1 \leq k\|x\|_{\infty}
\end{align*}
\section*{2 Probability Theory}
\subsection*{1)}
A = \{2, 4, 6\}; B = \{1, 2, 3, 4\} and C = \{1, 3, 5\}\\\\
$P(A) = \frac{3}{6} = \frac{1}{2}$\\\\
$P(B) = \frac{4}{6} = \frac{2}{3}$\\\\
$P(C) = \frac{3}{6} = \frac{1}{2}$\\\\
$P(A) \cdot P(B) = \frac{1}{3}$\\\\
$P(A) \cdot P(C) = \frac{1}{4}$\\\\
$P(A,B) = P(\{2,4\}) = \frac{2}{6} = \frac{1}{3}$\\\\
$P(A,C) = P(\{\}) = 0$\\

Because $P(A)\cdot P(B) = P(A,B)$, A and B are independent. Because $P(A) \cdot P(C) \neq P(A,C)$, A and C are \textbf{not} independent.

\subsection*{2)} We have facts:\\
$
P(Macintosh) = 0.3; P(Windows) = 0.5; P(Linux) = 0.2\\
P(virus|Macintosh) = 0.65; P(virus|Windows) = 0.82; P(virus|Linux) = 0.5\\\\
$
Then, we need to calculate $P(Windows|virus)$. We have:\\
\begin{align*}
P(Windows|virus) &= \frac{P(Windows,virus)}{P{virus}}\\
&= \frac{P(virus|Windows).P(Windows)}{P(virus,Macnitosh) + P(virus, Windows) + P(virus, Linux)}\\
&= \frac{P(virus|Windows).P(Windows)}{P(virus|Macnitosh).P(Macnitosh) + P(virus|Windows).P(Windows) + P(virus|Linux).P(Linux)}\\
&= \frac{0.82 \times 0.5}{0.65 \times 0.3 + 0.82 \times 0.5 + 0.5 \times 0.2}\\
& \approx 0.58 = 58\%
\end{align*}

\subsection*{3)}
(i) With:
\begin{align*}
f(x) =
\begin{cases}
      0, & \text{if}\ x<0 \\
      \frac{1}{1+x}, & \text{otherwise}
\end{cases}
\end{align*}
We need to verify whether $\int_{-\infty}^{\infty}f(x)dx = 1$.\\
We have: 
\begin{align*}
\int_{-\infty}^{\infty}f(x)dx &= \int_{0}^{\infty}\frac{1}{1+x}dx & \text{Because $f(x) = 0$ with $x < 0$}\\
&= ln(x+1) \Big|_{0}^{\infty}\\
&= ln(\infty + 1) - ln(0 + 1) \\ &= ln (\infty) \\& = \infty > 1
\end{align*}
Hence, $f(x)$ is not a valid PDF.
\newpage
(ii) With:
\begin{align*}
g(x) =
\begin{cases}
      0, & \text{if}\ x<0 \\
      \frac{1}{(1+x)^2}, & \text{otherwise}
\end{cases}
\end{align*}
We need to verify whether $\int_{-\infty}^{\infty}g(x)dx = 1$.\\
We have: 
\begin{align*}
\int_{-\infty}^{\infty}g(x)dx &= \int_{0}^{\infty}\frac{1}{(1+x)^2}dx & \text{Because $g(x) = 0$ with $x < 0$}\\
&= \frac{-1}{1 + x} \Big|_{0}^{\infty}\\
&= \frac{-1}{1 + \infty} - \frac{-1}{1 + 0} \\ 
&= 1 - \frac{1}{\infty} = 1
\end{align*}
Hence, $g(x)$ is a valid PDF.
Mean of $g(x)$:
\begin{align*}
E(X) &= \int_{0}^{\infty}x\frac{1}{(1+x)^2}dx & \text{Because $g(x) = 0$ with $x < 0$}\\
&= \int_{0}^{\infty}\frac{1 + x}{(1+x)^2}dx - \int_{0}^{\infty}\frac{1}{(1+x)^2}dx\\
&= \int_{0}^{\infty}\frac{1}{(1+x)}dx - \int_{0}^{\infty}\frac{1}{(1+x)^2}dx\\
&= ln(x+1) \Big|_{0}^{\infty} - \frac{-1}{1 + x} \Big|_{0}^{\infty}\\
&= \infty - 1 = \infty
\end{align*}
\subsection*{4)}
We have:\\
$P(Y = 1) = b$ and $P(Z = 1) = (1 - a)$ (Because x is uniformly distributed between (0,1)).

Also, $P(Y = 1,Z = 1) = P((0 < x < b)\ \&\ (a < x < 1)) = b - a$\\

Hence:\\
$P(Y = 1).P(Z = 1) = b(1 - a) = b - ab \neq b - a = P(Y = 1,Z = 1)$\\
So, Y and Z are \textbf{not} independent.

\subsection*{5)}
Because X and Y are independent, we have:
\begin{align*}
f_{XY}(x,y) = f_{X}(x) \cdot f_{Y}(y)
\end{align*}
Hence,
\begin{align*}
E(XY) &= \int_{-\infty}^{\infty}x \cdot y \cdot f_{XY}(x,y)dxdy\\ 
&= \int_{-\infty}^{\infty}x \cdot y \cdot f_{X}(x) \cdot f_{Y}(y)dxdy\\
&= \int_{-\infty}^{\infty}x \cdot f_{X}(x)dx \cdot \int_{-\infty}^{\infty}y \cdot f_{Y}(y)dy\\
&= E(X) \cdot E(Y)
\end{align*}
Covariance:
\begin{align*}
Cov(X,Y) &= E(XY) - E(X) \cdot E(Y)\\
&= 0 & \text{Because X and Y are independent, so E(XY) = E(X) $\cdot$ E(Y)}
\end{align*}
\section*{3 Multivariable Calculus}
Step 1 - Find critical points, i.e. both partial derivatives must be zero at those points:
$$J_f (x, y) = [f_x, f_y] = [3x^2 - 3y^2, -6xy] = [0, 0]$$
Which means
\begin{align}
3x^2 - 3y^2 &= 0\\
-6xy &= 0
\end{align}
Equation (2) is satisfied if $x=0$ or $y=0$. We consider these two solutions as two separate cases. For each case we will find solutions for equation (1).\\
\\
Case 1: Let $x=0$. We plug that into equation (1): $3 \cdot 0^3 - 3 y^2 = 0 \Leftrightarrow y = 0$. So if $x=0$, then $y=0$ in order to fulfill both equations. Therefore, $(0, 0)$ is a critical point.\\
\\
Case 2: Let $y=0$. We plug that into equation (1): $3 x^3 - 3 \cdot 0^2 = 0 \Leftrightarrow x = 0$. So we again get $(0, 0)$ as our critical point. Therefore, $(0,0)$ is our only critical point.\\
\\
Step 2 - Classify critical point:\\
In order to classify the critical point, we can try to do the second partial derivative test for two variables. For that we first need to compute the Hessian matrix of $f$:
$$H_f (x, y) = \begin{pmatrix}f_{xx}(x, y) & f_{xy}(x, y) \\ f_{yx}(x, y) & f_{yy}(x, y)\end{pmatrix} = \begin{pmatrix}6x & -6y \\ -6y & -6x\end{pmatrix}$$
Then we need to determine the defiteness of $H_f$ at the critical point $(0, 0)$:
$$\det(H_f(0, 0)) = \begin{vmatrix} 0 & 0 \\ 0 & 0 \end{vmatrix} = 0$$
Since $h_{11} = 0$ and $\det(H_f) = 0$, the second partial derivative test is unfortunately inconclusive.\\
\\
We can try to find the type of the point by a more geometric approach by looking what values $f$ takes arbitrarily near $(0,0)$:\\
\\
For $(x, y) = (a, 0), a > 0: f(x, y) = a^3 > 0$.\\
For $(x, y) = (a, 0), a < 0: f(x, y) = a^3 < 0$.\\
For $(x, y) = (0, b), b > 0: f(x, y) = 0$.\\
For $(x, y) = (0, b), b < 0: f(x, y) = 0$.\\
\\
Since $f$ stays 0 for $f(0, y)$ but takes values of $f(x, 0) < 0$ for $x < 0$ and $f(x, 0) > 0$ for $x > 0$, we can confirm that $(0, 0)$ is a saddle point.\\
\\
The maximum value $f$ can take is $\infty$, since $\lim_{x\to \infty} f(x, 0) =\lim_{x\to \infty} x^3 = \infty$.\\
Analog, the minimum value $f$ can take is $-\infty$, since $\lim_{x\to -\infty} f(x, 0) =\lim_{x\to -\infty} x^3 = -\infty$.
\end{document}



